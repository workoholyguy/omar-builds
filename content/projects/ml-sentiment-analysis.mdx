---
title: "Sentiment Analysis Pipeline"
slug: "ml-sentiment-analysis"
type: "ml"
roles:
  - ml
  - data
status: "demo"
featured: true
stack:
  - Python
  - TensorFlow
  - FastAPI
  - Docker
  - PostgreSQL
highlights:
  - "Achieved 89% accuracy on customer review classification"
  - "Processes 1000+ reviews per minute"
  - "Deployed as containerized microservice"
links:
  github: "https://github.com/omaradjei/sentiment-analysis"
dates:
  start: "2024-03"
  end: "2024-06"
metrics:
  accuracy: "89%"
  latency: "45ms"
tags:
  - python
  - tensorflow
  - nlp
  - fastapi
  - docker
description: "An ML pipeline for analyzing customer sentiment from product reviews with real-time inference API."
---

## Overview

A production-ready sentiment analysis system that classifies customer reviews as positive, negative, or neutral. Built with TensorFlow and deployed via FastAPI for real-time inference.

## Problem

Businesses receive thousands of customer reviews but lack the resources to manually analyze sentiment trends. Automated sentiment analysis helps identify issues early and track customer satisfaction over time.

## Solution

Developed an end-to-end ML pipeline that ingests reviews, preprocesses text, and classifies sentiment using a fine-tuned transformer model. The system includes batch processing for historical data and real-time API for new reviews.

## My Contributions

- Collected and preprocessed 50,000+ labeled reviews for training
- Fine-tuned DistilBERT model for sentiment classification
- Built FastAPI service with async request handling
- Implemented model versioning and A/B testing infrastructure
- Created monitoring dashboard for model performance

## Dataset & Evaluation

**Dataset:** Combined Amazon product reviews and Yelp reviews (50,000 samples, balanced classes)

**Evaluation:** 80/10/10 train/val/test split. Measured accuracy, F1-score, and confusion matrix. Cross-validated with 5-fold CV.

**Results:** 89% accuracy, 0.88 macro F1-score on held-out test set.

## Limitations

- Model struggles with sarcasm and context-dependent sentiment
- English-only support
- Performance degrades on very short reviews (<10 words)

## Challenges & Tradeoffs

**Challenge:** Balancing model accuracy vs inference latency for real-time use.

**Solution:** Used DistilBERT instead of full BERT, reducing latency by 60% with only 2% accuracy drop.

**Tradeoff:** Chose to optimize for precision on negative sentiment detection (catching complaints) over recall, accepting some false negatives.
